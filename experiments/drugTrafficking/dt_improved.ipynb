{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drug Traffiking experiment: improved model\n",
    "\n",
    "This notebooks contains the data processing, building and training part of the model used for the enhanced iteration of the drug traffiking experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import random\n",
    "import witwidget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from sklearn.model_selection import train_test_split\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from witwidget.notebook.visualization import WitWidget, WitConfigBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_scaler(data):\n",
    "  scaler = MinMaxScaler()\n",
    "  scaled = scaler.fit_transform(data)\n",
    "  return scaled\n",
    "\n",
    "def process_data(data):\n",
    "  x = data.loc[:, data.columns != 'Tipo salida 2']\n",
    "  y = data['Tipo salida 2']\n",
    "\n",
    "  x_cat = x[['Region', 'Defensor', 'Desarrollo','extranjero']]\n",
    "  x_cat['Region'] = label_encoder.fit_transform(x_cat['Region'])\n",
    "  x_cat['Defensor'] = label_encoder.fit_transform(x_cat['Defensor'])\n",
    "  x_cat['Desarrollo'] = label_encoder.fit_transform(x_cat['Desarrollo'])\n",
    "  x_cat['extranjero'] = label_encoder.fit_transform(x_cat['extranjero'])\n",
    "\n",
    "  x_num = x.loc[:, ~x.columns.isin(x_cat.columns)]\n",
    "\n",
    "  x_norm = minmax_scaler(x_num)\n",
    "  x_norm = pd.DataFrame(x_norm, columns = x_num.columns)\n",
    "\n",
    "  x_norm.reset_index(drop=True, inplace=True)\n",
    "  x_cat.reset_index(drop=True, inplace=True)\n",
    "\n",
    "  x_fin = pd.concat([x_norm, x_cat], axis = 1)\n",
    "  #y_fin = label_encoder.fit_transform(y)\n",
    "\n",
    "  return x_fin\n",
    "\n",
    "def custom_predict(examples_to_infer):\n",
    "\n",
    "  preds = model1.predict(model_inputs)\n",
    "  preds = [[1 - pred[0], pred[0]] for pred in preds]\n",
    "  return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'traficoDrogas.csv'\n",
    "\n",
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cambiando las dos RM a una sola\n",
    "\n",
    "data['Región (tribunal)']=data['Región (tribunal)'].replace('Metropolitana Sur','Metropolitana')\n",
    "data['Región (tribunal)']=data['Región (tribunal)'].replace('Metropolitana Norte','Metropolitana')\n",
    "\n",
    "## Sacar filas erróneas\n",
    "\n",
    "data.drop(16690, inplace=True)\n",
    "data.drop(16691, inplace=True)\n",
    "\n",
    "## Agregar variable edad\n",
    "\n",
    "data['Edad'] = np.nan\n",
    "\n",
    "mu = 27 ## Edad promedio entre 18 y 34 años (concentran la mayoría de consumo de drogas) (estudio drogas senda 2020)\n",
    "sigma = 8\n",
    "random.seed(23)\n",
    "\n",
    "for i in range(len(data)):\n",
    "    data['Edad'][i] = round(max(18, min(np.random.normal(mu, sigma), 65)))\n",
    "\n",
    "## Agregar variable extranjero\n",
    "\n",
    "data['Extranjero'] = np.nan\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if data['P.S. Expulsión'][i] == 'N':\n",
    "        data['Extranjero'][i] = 'No'\n",
    "    else:\n",
    "        data['Extranjero'][i] = 'Sí'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data.columns[[2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]], axis=1, inplace=True)\n",
    "data.rename(columns = {'Región (tribunal)':'Region', 'Grado desarrollo':'Desarrollo'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = data.loc[:, ~data.columns.isin(['Tipo salida 1', 'Tipo salida 2'])]\n",
    "y1 = data.loc[:, data.columns.isin(['Tipo salida 1', 'Tipo salida 2'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x1, y1['Tipo salida 2'], test_size=0.3, random_state = 23)\n",
    "\n",
    "## Del set de entrenamiento, se desprenden 1000 datos para generar un dataset de validación\n",
    "\n",
    "x_val1 = x_train1[-1000:]\n",
    "y_val1 = y_train1[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cat_train = x_train1[['Region', 'Defensor', 'Desarrollo','Extranjero']]\n",
    "x_cat_test = x_test1[['Region', 'Defensor', 'Desarrollo','Extranjero']]\n",
    "x_cat_val = x_val1[['Region', 'Defensor', 'Desarrollo','Extranjero']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "x_cat_train['Region'] = label_encoder.fit_transform(x_cat_train['Region'])\n",
    "x_cat_train['Defensor'] = label_encoder.fit_transform(x_cat_train['Defensor'])\n",
    "x_cat_train['Desarrollo'] = label_encoder.fit_transform(x_cat_train['Desarrollo'])\n",
    "x_cat_train['Extranjero'] = label_encoder.fit_transform(x_cat_train['Extranjero'])\n",
    "\n",
    "x_cat_test['Region'] = label_encoder.fit_transform(x_cat_test['Region'])\n",
    "x_cat_test['Defensor'] = label_encoder.fit_transform(x_cat_test['Defensor'])\n",
    "x_cat_test['Desarrollo'] = label_encoder.fit_transform(x_cat_test['Desarrollo'])\n",
    "x_cat_test['Extranjero'] = label_encoder.fit_transform(x_cat_test['Extranjero'])\n",
    "\n",
    "x_cat_val['Region'] = label_encoder.fit_transform(x_cat_val['Region'])\n",
    "x_cat_val['Defensor'] = label_encoder.fit_transform(x_cat_val['Defensor'])\n",
    "x_cat_val['Desarrollo'] = label_encoder.fit_transform(x_cat_val['Desarrollo'])\n",
    "x_cat_val['Extranjero'] = label_encoder.fit_transform(x_cat_val['Extranjero'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_num_train = x_train1.loc[:, ~x_train1.columns.isin(x_cat_train.columns)]\n",
    "x_num_test = x_test1.loc[:, ~x_test1.columns.isin(x_cat_test.columns)]\n",
    "x_num_val = x_val1.loc[:, ~x_val1.columns.isin(x_cat_val.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm_train = minmax_scaler(x_num_train)\n",
    "x_norm_train = pd.DataFrame(x_norm_train, columns = x_num_train.columns)\n",
    "\n",
    "x_norm_test = minmax_scaler(x_num_test)\n",
    "x_norm_test = pd.DataFrame(x_norm_test, columns = x_num_test.columns)\n",
    "\n",
    "x_norm_val = minmax_scaler(x_num_val)\n",
    "x_norm_val = pd.DataFrame(x_norm_val, columns = x_num_val.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm_train.reset_index(drop=True, inplace=True)\n",
    "x_cat_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "x_norm_test.reset_index(drop=True, inplace=True)\n",
    "x_cat_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "x_norm_val.reset_index(drop=True, inplace=True)\n",
    "x_cat_val.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_fin = pd.concat([x_norm_train, x_cat_train], axis = 1)\n",
    "x_test_fin = pd.concat([x_norm_test, x_cat_test], axis = 1)\n",
    "x_val_fin = pd.concat([x_norm_val, x_cat_val], axis = 1)\n",
    "\n",
    "y_train_fin = label_encoder.fit_transform(y_train1)\n",
    "y_test_fin = label_encoder.fit_transform(y_test1)\n",
    "y_val_fin = label_encoder.fit_transform(y_val1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using AIF360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = BinaryLabelDataset(\n",
    "    df = pd.concat([x_train_fin,pd.DataFrame(y_train_fin, columns = ['Tipo salida 2'])], axis = 1),\n",
    "    label_names = ['Tipo salida 2'],\n",
    "    protected_attribute_names = ['Region_alt'], #['Extranjero'],\n",
    "    favorable_label = 1,\n",
    "    unfavorable_label = 0\n",
    ")\n",
    "\n",
    "privileged_groups = [{'Region_alt': 1}] #[{'Extranjero': 1}]\n",
    "unprivileged_groups = [{'Region_alt': 0}] #[{'Extranjero': 0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_train,\n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "\n",
    "# Métrica de equidad (mean difference)\n",
    "metric_f = metric_orig_train.mean_difference()\n",
    "print(\"Diferencia en los resultados medios entre grupos privilegiados y no privilegiados = %f\" % metric_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "\n",
    "dataset_transf_train = RW.fit_transform(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_transf_train,\n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "# Métrica de equidad (mean difference)\n",
    "metric_f_2 = metric_orig_train.mean_difference()\n",
    "\n",
    "print(\"Diferencia en los resultados medios entre grupos privilegiados y no privilegiados = %f\" % metric_f_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_fin.drop(columns = ['Region_alt'], inplace = True)\n",
    "x_test_fin.drop(columns = ['Region_alt'], inplace = True)\n",
    "x_val_fin.drop(columns = ['Region_alt'], inplace = True)\n",
    "\n",
    "# x_train_fin.drop(columns = ['Extranjero'], inplace = True)\n",
    "# x_test_fin.drop(columns = ['Extranjero'], inplace = True)\n",
    "# x_val_fin.drop(columns = ['Extranjero'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fin =  pd.concat([x_train_fin, pd.DataFrame(y_train_fin, columns = ['Tipo salida 2'])], axis = 1)\n",
    "train_fin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes1 = 1\n",
    "num_features1 = x_train_fin.shape[1]\n",
    "num_output1 = 1\n",
    "\n",
    "num_layers_01 = 14\n",
    "num_layers_11 = 12\n",
    "\n",
    "epochs1 = 70\n",
    "learning_rate1 = 0.01\n",
    "batch_size1 = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1 = keras.Input(shape = (num_features1,), name = \"data\")\n",
    "\n",
    "x11 = layers.Dense(num_layers_01, activation = \"relu\", name = \"dense_1\")(inputs1)\n",
    "x21 = layers.Dense(num_layers_11, activation = \"relu\", name = \"dense_2\")(x11)\n",
    "\n",
    "outputs1 = layers.Dense(num_output1, activation = \"sigmoid\", name = \"predictions\")(x21)\n",
    "\n",
    "model1 = keras.Model(inputs = inputs1, outputs = outputs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight(class_weight = 'balanced', classes = np.unique(y_train_fin), y = y_train_fin)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "sample_weight = dataset_transf_train.instance_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compilando el modelo\n",
    "\n",
    "model1.compile(\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = learning_rate1),\n",
    "    loss = keras.losses.BinaryCrossentropy(from_logits = False),\n",
    "    metrics = [keras.metrics.Precision(name='precision_05', thresholds=0.5),\n",
    "               keras.metrics.Precision(name='precision_025', thresholds=0.25),\n",
    "               keras.metrics.Recall(name='recall_05', thresholds=0.5),\n",
    "               keras.metrics.Recall(name='recall_025', thresholds=0.25),\n",
    "               keras.metrics.FalseNegatives(name='fn_05', thresholds=0.5),\n",
    "               keras.metrics.FalseNegatives(name='fn_025', thresholds=0.25),\n",
    "               keras.metrics.BinaryAccuracy(name='accuracy_05', threshold=0.5),\n",
    "               keras.metrics.BinaryAccuracy(name='accuracy_025', threshold=0.25)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenando el modelo\n",
    "\n",
    "training1 = model1.fit(\n",
    "    x_train_fin,\n",
    "    y_train_fin,\n",
    "    batch_size = batch_size1,\n",
    "    epochs = epochs1,\n",
    "    class_weight = class_weights,\n",
    "    sample_weight = sample_weight,\n",
    "    validation_data = (x_val_fin, y_val_fin)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generando predicciones\n",
    "\n",
    "predict_train1 = (model1.predict(x_train_fin) > 0.5).astype(int)\n",
    "predict_test1 = (model1.predict(x_test_fin) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Matriz de confusión para dataset de entrenamiento 1\n",
    "\n",
    "print(confusion_matrix(y_train_fin,predict_train1))\n",
    "print(classification_report(y_train_fin,predict_train1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Matriz de confusión para dataset de prueba 1\n",
    "\n",
    "print(confusion_matrix(y_test_fin,predict_test1))\n",
    "print(classification_report(y_test_fin,predict_test1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Fairlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocess_est = ThresholdOptimizer(\n",
    "    estimator=model1,\n",
    "    constraints=\"false_negative_rate_parity\",  # Optimize FPR and FNR simultaneously\n",
    "    objective=\"accuracy_score\",\n",
    "    prefit=True,\n",
    "    predict_method=\"predict\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocess_est.fit(x_train_fin, y_train_fin, sensitive_features = x_train_fin['Region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train2 = postprocess_est.predict(x_train_fin, sensitive_features = x_train_fin['Region'])\n",
    "predict_test2 = postprocess_est.predict(x_test_fin, sensitive_features = x_test_fin['Region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Matriz de confusión para dataset de entrenamiento 2\n",
    "\n",
    "print(confusion_matrix(y_train_fin,predict_train2))\n",
    "print(classification_report(y_train_fin,predict_train2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Matriz de confusión para dataset de prueba 2\n",
    "\n",
    "print(confusion_matrix(y_test_fin,predict_test2))\n",
    "print(classification_report(y_test_fin,predict_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving results and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = pd.DataFrame(predict_test1, columns=['score'])\n",
    "\n",
    "x_test1_alt = x_test1.reset_index(drop=True)\n",
    "y_test1_alt = y_test1.reset_index(drop=True)\n",
    "\n",
    "test = pd.concat([x_test1_alt, test_results, pd.DataFrame(y_test_fin)], axis = 1)\n",
    "\n",
    "path2 = r'preds_dt_improved.csv'\n",
    "test.to_csv(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('dt_improved.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(model1, x_train_fin.values[:])\n",
    "shap_values = explainer(x_train_fin.values[:])\n",
    "shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values.feature_names = list(x_train_fin.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_df = pd.DataFrame(shap_values.values, columns=shap_values.feature_names)\n",
    "\n",
    "# Calcular el valor absoluto y luego el promedio para cada característica\n",
    "shap_abs_avg = shap_df.abs().mean()\n",
    "shap_avg = shap_df.mean()\n",
    "shap_max = shap_df.max()\n",
    "shap_min= shap_df.min()\n",
    "\n",
    "print('Media absoluta: ', '\\n\\n', shap_abs_avg)\n",
    "print('----------------------------------')\n",
    "print('Media: ', '\\n\\n', shap_avg)\n",
    "print('----------------------------------')\n",
    "print('Máximo: ', '\\n\\n', shap_max)\n",
    "print('----------------------------------')\n",
    "print('Mínimo: ', '\\n\\n', shap_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"dt_improved_shap.pdf\", bbox_inches=\"tight\", format=\"pdf\")  # o \"shap_plot.svg\" para formato SVG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_datapoints = 5007\n",
    "tool_height_in_px = 750\n",
    "\n",
    "examples_labels = pd.concat([x_test_fin.reset_index(drop=True), pd.DataFrame(y_test_fin, columns = ['Tipo salida 2']).reset_index(drop=True)], axis=1)\n",
    "columns_not_for_model_input = [examples_labels.columns.get_loc('Tipo salida 2')]\n",
    "\n",
    "examples_wit = examples_labels.values.tolist()\n",
    "column_names = examples_labels.columns.tolist()\n",
    "\n",
    "model_inputs = np.delete(np.array(examples_wit[:num_datapoints]), columns_not_for_model_input, axis=1)\n",
    "\n",
    "def custom_predict_shap(examples_to_infer):\n",
    "\n",
    "  preds = model1.predict(model_inputs)\n",
    "  preds = [[1 - pred[0], pred[0]] for pred in preds]\n",
    "\n",
    "  shap_output = explainer(model_inputs)\n",
    "  attributions = []\n",
    "  for single_shap_output in shap_output:  # iteramos sobre cada resultado de shap (cada ejemplo)\n",
    "    attrs = {}\n",
    "    for i, col in enumerate(x_train_fin.columns):\n",
    "      attrs[col] = single_shap_output.values[i]  # utilizamos single_shap_output.values\n",
    "    attributions.append(attrs)\n",
    "\n",
    "  ret = {'predictions': preds, 'attributions': attributions}\n",
    "\n",
    "  return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the tool with the test examples and the trained classifier\n",
    "\n",
    "config_builder = WitConfigBuilder(examples_wit[:num_datapoints],column_names).set_custom_predict_fn(custom_predict_shap).set_target_feature('Tipo salida 2')\n",
    "WitWidget(config_builder, height=tool_height_in_px)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
